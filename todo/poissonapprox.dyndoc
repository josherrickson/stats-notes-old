~~~~
<<dd_ignore>>
---
title: When can Poisson Regression approximate Logistic?
author: Josh Errickson
output:
  html_document:
    toc: yes
    toc_depth: 4
    toc_float: yes
---
<</dd_ignore>>
~~~~

An older idea in Epidemiology is to use a Poisson regression model in place of a logistic regression model. This idea has some validity because with a low mean, the Poisson distribution approximates the binary distribution.

^#^ Simulation

Let's examine this. First, we define a program which generates some data according to a logistic model, then fits both logistic and Poisson regression models against it.

This program, defined below, takes in three arguments
- `n` - Sample size
- `p` - Baseline probability of success
- `b1` - Coefficient of interest.

The model is simply

\[
logit(P(Y = 1 | X)) = logit(p) + b_1x
\]

~~~~
<<dd_do>>
program def binsim, rclass
	drop _all
	args n p b1
	set obs `n'
	gen x = rnormal()
	gen y = rbinomial(1, invlogit(logit(`p') + `b1'*x))
	* Return P(success) to ensure everything is working
	mean y
	mat b = e(b)
	scalar pp = b[1,1]
	return scalar pp=pp

	* Poisson model
	poisson y x
	mat b = e(b)
	scalar b_pois = b[1,1]
	return scalar b_pois=b_pois

	* Logistic model
	logistic y x
	mat b = e(b)
	scalar b_logit = b[1,1]
	return scalar b_logit=b_logit
end
<</dd_do>>
~~~~

^#^ Results

Now we can run it with a few different settings. Specifically, we're interested in how close to 0 the mean must be for the Poisson coefficient to approximate the logistic coefficient.

Set a few parameters

~~~~
<<dd_do>>
local beta1 .4
local reps 1000
<</dd_do>>
~~~~

^#^^#^ 10% success

~~~~
<<dd_do>>
simulate pp=r(pp) b_pois=r(b_pois) b_logit=r(b_logit), reps(`reps') nodots: binsim 10000 .1 `beta1'
<</dd_do>>
~~~~

First we'll ensure the code is working and that P(success) is 10% as requested.

~~~~
<<dd_do>>
mean pp
<</dd_do>>
~~~~

Now we can look at the kernel densities

~~~~
<<dd_do>>
twoway kdensity b_logit || kdensity b_pois, xline(`beta1') legend(label(1 "Logistic") label(2 "Poisson"))
<</dd_do>>
~~~~

<<dd_graph>>

The Poisson coefficient is strongly negatively biased. We can estimate the bias as a percent of the true coefficient.

~~~~
<<dd_do>>
gen error = abs(b_logit - b_pois)/b_logit
mean error
<</dd_do>>
~~~~

^#^^#^ 5% success

~~~~
<<dd_do>>
simulate pp=r(pp) b_pois=r(b_pois) b_logit=r(b_logit), reps(`reps') nodots: binsim 10000 .05 `beta1'
mean pp
twoway kdensity b_logit || kdensity b_pois, xline(`beta1') legend(label(1 "Logistic") label(2 "Poisson"))
gen error = abs(b_logit - b_pois)/b_logit
mean error
<</dd_do>>
~~~~

<<dd_graph>>

Still see a negative bias.

^#^^#^ 3% success

~~~~
<<dd_do>>
simulate pp=r(pp) b_pois=r(b_pois) b_logit=r(b_logit), reps(`reps') nodots: binsim 10000 .03 `beta1'
mean pp
twoway kdensity b_logit || kdensity b_pois, xline(`beta1') legend(label(1 "Logistic") label(2 "Poisson"))
gen error = abs(b_logit - b_pois)/b_logit
mean error
<</dd_do>>
~~~~

<<dd_graph>>

The bias is minimal but still present.

^#^^#^ 1% success

~~~~
<<dd_do>>
simulate pp=r(pp) b_pois=r(b_pois) b_logit=r(b_logit), reps(`reps') nodots: binsim 10000 .01 `beta1'
mean pp
twoway kdensity b_logit || kdensity b_pois, xline(`beta1') legend(label(1 "Logistic") label(2 "Poisson"))
gen error = abs(b_logit - b_pois)/b_logit
mean error
<</dd_do>>
~~~~

<<dd_graph>>

The bias has all but disappeared.

^#^ Conclusion

I wouldn't recommend using Poisson over Logistic unless P(Success) was 1% or less.

There's an interesting artifact to explore, namely that the percent bias is consistently about 15-20% larger than the true beta.
